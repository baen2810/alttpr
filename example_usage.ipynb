{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALttPR example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Union\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pickle\n",
    "\n",
    "# def to_tstr(ts):\n",
    "#     tsn = ts\n",
    "#     if type(ts) == pd.Timedelta:\n",
    "#         tsn = pd.Timestamp('1900-01-01') + ts\n",
    "#     return tsn.strftime('%H:%M:%S')\n",
    "\n",
    "# class RacetimeCrawler:\n",
    "#     def __init__(self) -> None:\n",
    "#         self.host_ids: List[str] = []\n",
    "#         self.hosts_df: pd.DataFrame = pd.DataFrame()\n",
    "#         self.output_path: Path = Path(os.getcwd(), 'export')\n",
    "#         self.base_url: str = r\"https://racetime.gg/user/\"\n",
    "#         self.last_updated: pd.Timestamp = pd.Timestamp.now()\n",
    "\n",
    "#     def get(self, host_ids: Union[str, List[str]]) -> None:\n",
    "#         self.host_ids = [host_ids] if isinstance(host_ids, str) else host_ids\n",
    "#         all_hosts_data = []\n",
    "#         for host_id in self.host_ids:\n",
    "#             url = self.base_url + host_id\n",
    "#             response = self._scrape(url)\n",
    "#             soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#             if response.status_code == 200:\n",
    "#                 n_pages = int(soup.find(\"div\", {\"class\": \"pagination\"}).decode_contents().strip().split(' of ')[1].split('\\n')[0])\n",
    "#                 host_name = soup.find(\"div\", {\"class\": \"user-profile\"}).find(\"span\", {\"class\": \"name\"}).text\n",
    "#                 cols = [v.text.lower().replace(' ', '_') for v in soup.find('aside').find_all('dt')[1:]]\n",
    "#                 vals = [int(v.text.split(' ')[0]) for v in soup.find('aside').find_all('dd')[1:]]\n",
    "#                 df_user_stats = pd.DataFrame([vals], columns=cols)\n",
    "#                 df_user = pd.DataFrame([[host_id, host_name, n_pages]], columns=['host_id', 'host_name', 'n_pages'])\n",
    "#                 df_user_stats = pd.concat([df_user, df_user_stats], axis=1)\n",
    "#                 all_hosts_data.append(df_user_stats)\n",
    "#             else:\n",
    "#                 raise ValueError(f'unable to process host_id \\'{host_id}\\'')\n",
    "#         self.hosts_df = pd.concat(all_hosts_data, ignore_index=True)\n",
    "#         self.last_updated = pd.Timestamp.now()  # Update the last_updated attribute\n",
    "\n",
    "#     def _scrape(self, url: str) -> requests.Response:\n",
    "#         return requests.get(url)\n",
    "    \n",
    "#     def set_output_path(self, path: Union[Path, str]) -> None:\n",
    "#         self.output_path = Path(path)\n",
    "\n",
    "#     def export(self, path: Union[Path, str] = None) -> None:\n",
    "#         if path:\n",
    "#             self.set_output_path(path)\n",
    "#         if not self.output_path.exists():\n",
    "#             self.output_path.mkdir(parents=True)\n",
    "#         export_path = Path(self.output_path, 'hosts_df.xlsx')\n",
    "#         self.hosts_df.to_excel(export_path, index=False, engine='openpyxl')\n",
    "#         print(f'Exported data to: {self.output_path}')\n",
    "\n",
    "#     def save(self) -> None:\n",
    "#         if not self.output_path.exists():\n",
    "#             self.output_path.mkdir(parents=True)\n",
    "#         save_path = Path(self.output_path, 'racetime_crawler.pkl')\n",
    "#         with open(save_path, 'wb') as f:\n",
    "#             pickle.dump(self, f)\n",
    "#         print(f'Crawler object saved to: {save_path}')\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def load(path: Union[Path, str]) -> 'RacetimeCrawler':\n",
    "#         with open(path, 'rb') as f:\n",
    "#             crawler = pickle.load(f)\n",
    "#         print(f'Crawler object loaded from: {path}')\n",
    "#         return crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XzVwZWqJmkB5k8eb', 'jb8GPMWwXbB1nEk0']\n",
      "c:\\Users\\Weissb\\OneDrive\\Dokumente\\Projekte\\alttpr\\export\n",
      "Exported data to: c:\\Users\\Weissb\\OneDrive\\Dokumente\\Projekte\\alttpr\\export\n",
      "Crawler object saved to: c:\\Users\\Weissb\\OneDrive\\Dokumente\\Projekte\\alttpr\\export\\racetime_crawler.pkl\n",
      "Crawler object loaded from: export/racetime_crawler.pkl\n",
      "['XzVwZWqJmkB5k8eb', 'jb8GPMWwXbB1nEk0']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "from alttpr.crawlers import RacetimeCrawler\n",
    "crawler = RacetimeCrawler()\n",
    "crawler.get(host_ids=[\"XzVwZWqJmkB5k8eb\", \"jb8GPMWwXbB1nEk0\"])\n",
    "print(crawler.host_ids)  # Output: ['XzVwZWqJmkB5k8eb', 'jb8GPMWwXbB1nEk0']\n",
    "print(crawler.output_path)  # Output: Current working directory path\n",
    "# print(crawler.hosts_df)  # Output: DataFrame with combined hosts data\n",
    "\n",
    "crawler.export()\n",
    "# The DataFrame is exported to 'export_directory/hosts_df.xlsx'\n",
    "\n",
    "# Save the crawler object\n",
    "crawler.save()\n",
    "\n",
    "# Load the crawler object\n",
    "loaded_crawler = RacetimeCrawler.load(\"export/racetime_crawler.pkl\")\n",
    "print(loaded_crawler.host_ids)  # Output: ['XzVwZWqJmkB5k8eb', 'jb8GPMWwXbB1nEk0']\n",
    "# print(loaded_crawler.hosts_df)  # Output: DataFrame with combined hosts data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
